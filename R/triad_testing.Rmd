---
title: "Triad testing for ChatGPT"
author: "Jasper Robbins"
date: "2023-08-21"
---

```{r setup, include=FALSE,echo=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(httr)
library(jsonlite)
library(dplyr)
library(stringr)
library(future)
library(future.apply)
source("./functions/processing_helpers.R")
source("./functions/gpt_helpers.R")
```


# Add your API Key here.
```{r setup api key}
# Replace this API key with the one you received when registering.
api_key <- "sk-..."
```

## Read data in from file.
```{r import data}
triad_data <- process_triad_data(
  ""
)
```

# Update your prompt to ChatGPT here.
```{r format prompt}
prompt_start <- "We are going to present you with three nouns. Your task is to analyze the word meaning of all possible noun pairs in the triad, and select the odd word out.
Following are the steps to complete the task:
Step 1: Closely analyze the words in the triad.
Step 2: On the basis of step 1, state the odd word out with no further explanation.

You are ready to complete the task. Explain the process of each step, and end your response by stating the odd word out with no explanation.
Following is the triad: 
"
prompt_end <- ""

# Generate a dataframe of prompts
prompts <- generate_prompts(triad_data, prompt_start, prompt_end)
```


## Adjust specs and generate prompts
```{R prompt building}

# NOTE: This specifies how we will read chatgpt's output and find the answer.
# There are some options, but you must be specific in prompting if changing this.
# odd     - ask for the odd word out, tell chatgpt to state the odd word at the end without further explanation.
# basic   - ask for only the most similar pair, this will search for {word1, word2} in the response.
# explain - ask for an explanation of each word pair's relatedness, followed by selection.
prompt_method = "odd"

# Optionally filter triads
triad_data <- triad_data %>% filter(dataset %in% c("abstract"))

# Change ChatGPT settings
gpt_model = "gpt-3.5-turbo"
gpt_temperature = 0

cat("You have", nrow(prompts), "triads with", 6*nrow(prompts), "prompts")

```
## Query ChatGPT on ALL prompts
```{r query}
# Prepare batches of prompts
concurrent <- 20
p <- prompts %>% select(-regex)
num_batches <- nrow(p)/concurrent

# Setup
plan(multisession)
responses = tibble()
overall_start <- Sys.time()

# Query ChatGPT
## If this freezes, change '1:num_batches' to '2:num_batches' or however many
## sets of 20 your code finished before freezing. Data is saved as you go.
## e.g., if it freezes on 61-80, change it to (3:num_batches).
for (i in (1:num_batches)) {
  start_idx <- seq(concurrent*(i-1)+1, concurrent*(i-1)+concurrent)
  print(range(start_idx))
  testing <- fast_query(tibble(p)[start_idx,])
  
  responses <- bind_rows(responses, testing)
}
```

## Process Response Data
```{r process responses}
# Tibble to store results
responses_tibble <- responses[[1]]
results <- tibble(
  AB = double(),
  AC = double(),
  BC = double(),
  answer = character()
)

# Process Responses
for (i in (1:length(responses_tibble))) {
  processed_responses <- mapply(
  function(item, regex) process_response(
      item,
      regex,
      prompt_method
    ),
    responses_tibble[[i]],
    prompts[i,]$regex,
    SIMPLIFY = FALSE
  )
  row_results <- as_tibble(unlist(lapply(processed_responses, function(x) x$triad_results[[1]])))
  
  if (prompt_method == "odd") {
    row_results <- row_results %>%
    mutate(
      coded_answer = str_c(
      ifelse(grepl(triad_data$A[i], value), "", "A"),
      ifelse(grepl(triad_data$B[i], value), "", "B"),
      ifelse(grepl(triad_data$C[i], value), "", "C"),
      sep = ""
      )
    ) %>% 
      group_by(coded_answer) %>%
      summarize(count = n())
  } else {
    row_results <- row_results %>%
    mutate(
      coded_answer = str_c(
      ifelse(grepl(triad_data$A[i], value), "A", ""),
      ifelse(grepl(triad_data$B[i], value), "B", ""),
      ifelse(grepl(triad_data$C[i], value), "C", ""),
      sep = ""
      )
    ) %>% 
      group_by(coded_answer) %>%
      summarize(count = n())
  }
  
  highest_count <- row_results %>% 
    arrange(desc(count)) %>%
    slice(1)
  
  freqs <- format_frequencies(row_results)
  
  results <- results %>%
    add_row(
      AB = freqs[freqs$coded_answer == "AB", ]$count,
      AC = freqs[freqs$coded_answer == "AC", ]$count,
      BC = freqs[freqs$coded_answer == "BC", ]$count,
      answer = highest_count$coded_answer
  )
  
}

```

## Run data analysis
```{r data analysis}
################### Figure out how to do fisher exact tests ####################
expected <- triad_data %>% 
  select(pAB, pAC, pBC) %>% 
  mutate_all(~ . *6)
observed <- results

```

## Display results
```{r results}
# Cherrypick initial data for output
data <- triad_data %>%
  select(A, B, C, difficulty, human_coded_answer, dataset, category, pAB, pAC, pBC) %>% 
  add_column(
    gpt_pAB = results$AB,
    gpt_pAC = results$AC,
    gpt_pBC = results$BC,
    gpt_coded_answer = results$answer,
    correct = NA,
    #gpt_answer = NA,
) %>% 
  rowwise %>% 
  mutate(
    correct = grepl(gpt_coded_answer, human_coded_answer)
  )

# Incorrect response data
datafalse <- data %>%
  filter(correct == "FALSE") %>%
  select(
    correct,
    dataset,
    category,
    A, B, C,
    human_coded_answer,
    gpt_coded_answer,
    #gpt_answer,
  )

# Accuracy by triad category
percentage_by_category <- data %>%
  group_by(category) %>%
  summarise(
    accuracy = round(sum(correct, na.rm = TRUE) / n(), 2),
    count = n(),
  ) %>%
  select(category, accuracy, count)

# Accuracy by answer (checking for word order bias)
percentage_by_answer <- data %>%
  group_by(human_coded_answer) %>%
  summarise(
    accuracy = round(sum(correct, na.rm = TRUE) / n(), 2),
    count = n(),
  ) %>%
  select(human_coded_answer, accuracy, count)

# Summary stats data
summary_stats <- tibble(
  "------OVERALL------" = "----------------------------",
  score = paste(sum(data$correct, na.rm = TRUE), "/", nrow(triad_data)),
  percentage = paste(
    100 * sum(data$correct, na.rm = TRUE) / nrow(triad_data),
    "%"
  ),
  "-------OTHER-------" = "----------------------------",
  avg_correct_difficulty = round(
    mean(data$difficulty[data$correct], na.rm = TRUE), 
    2
  ),
  avg_incorrect_difficulty = round(
    mean(data$difficulty[!data$correct], na.rm = TRUE), 
    2
  ),
  "AB_%" = percentage_by_answer$accuracy[
    percentage_by_answer$human_coded_answer == "AB,"
  ],
  "AC_%" = percentage_by_answer$accuracy[
    percentage_by_answer$human_coded_answer == "AC,"
  ],
  "BC_%" = percentage_by_answer$accuracy[
    percentage_by_answer$human_coded_answer == "BC,"
  ],
) %>%
  mutate(across(everything(), toString)) %>%
  pivot_longer(
    everything(),
    names_to = "stat",
    values_to = "value"
  )

# % by correct by the category of the triad in prompt
print(percentage_by_category)

# % by correct by the code of the triad answer
print(percentage_by_answer)

# Incorrect response data
print(datafalse)

# Overall summary stats
print(summary_stats)

data
    
```