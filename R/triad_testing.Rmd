---
title: "Triad testing for ChatGPT"
author: "Jasper Robbins"
date: "2023-08-21"
---

```{r setup, include=FALSE,echo=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(httr)
library(jsonlite)
library(dplyr)
library(stringr)
source("./functions/processing_helpers.R")
source("./functions/gpt_helpers.R")
```

## Add your API Key here
```{r setup api key}
# Replace this API key with the one you received when registering.
api_key <- "sk-..."
```

## Read data from file
```{r import data}
triad_data <- process_triad_data(
  "your_file_path"
)
```


## Edit the prompt template
```{r prompt template}

# Format a triad string for each row of format: '{word_A,word_B,word_C};'
triad_data <- triad_data %>%
  rowwise %>%
  mutate(
    triad = paste0("{", paste(A, B, C, sep = ","), "};", sep = "")
  )

# Update your prompt to ChatGPT here.
prompt_start <- "We are going to present you with three words. Your task is to analyse the meaning of all possible word pairs in the triad, and subsequently report the probability that you would choose each pair in the triad as more similar than the others. Your choice is to be based solely in terms of semantic word meaning. This means that phonemic or visual similarity of the words should not be factored into your choice.   
Here are the steps to complete the analysis:
Step 1: Closely scrutinize every possible pair in the triad.
Step 2: After detailed consideration, report the probability that you would select each pair as most semantically similar.
You will now be provided with two examples. Note that the specific probabilities of the provided examples are arbitrary for the sake of the example, and the probabilities in the example are not indicative of their true semantic similarity.
Example 1:
       	Presented: {Angel; Halo; Plate}
       	Response: {Angel – Halo: 0.60} {Angel – Plate: 0.20}, {Halo – Plate: 0.20}
Example 2:
Presented: {Hair; Cage; Cheap}
        	Response: {Hair – Cage: 0.15} {Hair – Cheap: 0.60} {Cage – Cheap: 0.25}
"
prompt_end <- ""
```

## NOTE - If you want to ask chatgpt to return the most similar pair, set similarity_scores to false. If you want to ask for similarity ratings for every word pair, set similarity_scores to true. This requires chatgpt to respond with {word_1 word_2 similarity_rating} for each triad.

## Adjust specs and generate prompts
```{R prompt building}

# Specify how many triads_per_prompt you want to ask per prompt
triads_per_prompt = 10

# Specify if using similarity scores for word-pairs
similarity_scores = TRUE

# Optionally filter triads, e.g.
triad_data <- triad_data %>% filter(dataset %in% c("abstract"))

# Generate a dataframe of prompts
prompts = generate_prompts(
  triad_data,
  triads_per_prompt, 
  prompt_start, 
  prompt_end
)

num_prompts = nrow(prompts)
cat("You have", num_prompts, "prompts.")
```


## Adjust gpt settings and check cost for full dataset
```{r gpt costing}
# Choose your gpt model
gpt_model <- "gpt-3.5-turbo" # or "gpt-4"

# I believe increases the variance between answers
gpt_temperature <- 0

# Check the cost
estimate_cost(
  gpt_model,
  nrow(prompts),
  paste(prompt_start, prompt_end),
  triads_per_prompt
)
```

## Query ChatGPT on a single prompt
```{r test query}
# Send one prompt request to ChatGPT
response <- ask_gpt(gpt_model, gpt_temperature, prompts[1, ], api_key)

# Process response and output a tibble
print(process_response(response, similarity_scores))

```

## Run testing, collect and process ChatGPT repsonse data
```{r data collection}
# Create dataframe to store results
data <- triad_data %>%
  select(A, B, C, difficulty, human_coded_answer, dataset, category) %>%
  add_column(
    gpt_answer = NA,
    gpt_coded_answer = NA,
    correct = NA,
    gpt_message = NA,
    position = NA
  )

cat("Processing", num_prompts, "prompts: ")

# For each prompt...
for (i in seq(1, num_prompts)) {

  # call to chatGPT
  response <- ask_gpt(gpt_model, gpt_temperature, prompts[i, ], api_key)

  # store its responses (both the full message and the individual answers)
  gpt_message <- process_response(response, similarity_scores)
  start <- (i - 1) * triads_per_prompt + 1
  row_range <- seq(start, min(start + triads_per_prompt - 1, nrow(data)))
  if (similarity_scores) {
    answers <- gpt_message %>% 
      group_by(group = (row_number() - 1) %/% 3) %>%
      filter(similarity == max(similarity)) %>%
      distinct(similarity, .keep_all = TRUE) %>%
      ungroup() %>%
      select(-group, -similarity)
  } else {
    answers <- gpt_message
  }
  
  data$gpt_answer[row_range] <- answers$word_pairs

  # For each triad...
  for (j in row_range) {

    # Convert the words into AB/AC/BC
    coded_answer <- str_c(
      ifelse(grepl(data$A[j], data$gpt_answer[j]), "A", ""),
      ifelse(grepl(data$B[j], data$gpt_answer[j]), "B", ""),
      ifelse(grepl(data$C[j], data$gpt_answer[j]), "C", ""),
      sep = ""
    )

    # Store the answer, and if it is correct
    data$gpt_coded_answer[j] <- coded_answer
    data$correct[j] <- grepl(coded_answer, data$human_coded_answer[j])
    data$gpt_message[j] <- content(response)$choices[[1]]$message$content
    data$position[j] <- (j - 1) %% triads_per_prompt + 1
  }

  cat(i, " ")
}

```

## Process and summarise results
```{r results}
datafalse <- data %>%
  filter(correct == "FALSE") %>%
  select(
    correct,
    dataset,
    category,
    A, B, C,
    human_coded_answer,
    gpt_coded_answer
  )

```

percentage_by_category <- data %>%
  group_by(category) %>%
  summarise(
    accuracy = round(sum(correct, na.rm = TRUE) / n(), 2),
    count = n(),
  ) %>%
  select(category, accuracy, count)

percentage_by_answer <- data %>%
  group_by(human_coded_answer) %>%
  summarise(
    accuracy = round(sum(correct, na.rm = TRUE) / n(), 2),
    count = n(),
  ) %>%
  select(human_coded_answer, accuracy, count)

percentage_by_position <- data %>%
  group_by(position) %>%
  summarise(
    accuracy = round(sum(correct, na.rm = TRUE) / n(), 2),
    count = n(),
  ) %>%
  select(position, accuracy, count)

positional_pearson <- cor.test(
  percentage_by_position$position,
  percentage_by_position$accuracy,
  method = "pearson"
)

summary_stats <- tibble(
  "------OVERALL------" = "----------------------------",
  score = paste(sum(data$correct, na.rm = TRUE), "/", nrow(triad_data)),
  percentage = paste(
    100 * sum(data$correct, na.rm = TRUE) / nrow(triad_data),
    "%"
  ),
  "-------OTHER-------" = "----------------------------",
  avg_correct_difficulty = round(
    mean(data$difficulty[data$correct], na.rm = TRUE), 
    2
  ),
  avg_incorrect_difficulty = round(
    mean(data$difficulty[!data$correct], na.rm = TRUE), 
    2
  ),
  "AB_%" = percentage_by_answer$accuracy[
    percentage_by_answer$human_coded_answer == "AB,"
  ],
  "AC_%" = percentage_by_answer$accuracy[
    percentage_by_answer$human_coded_answer == "AC,"
  ],
  "BC_%" = percentage_by_answer$accuracy[
    percentage_by_answer$human_coded_answer == "BC,"
  ],
  triad_position_pearson = paste(
    "r:", format(round(positional_pearson$estimate, 2), nsmall = 2), "|",
    "p:", format(round(positional_pearson$p.value, 3), nsmall = 3)
  ),
) %>%
  mutate(across(everything(), toString)) %>%
  pivot_longer(
    everything(),
    names_to = "stat",
    values_to = "value"
  )

# % by correct by the position of the triad in prompt
print(percentage_by_position)

# % by correct by the category of the triad in prompt
print(percentage_by_category)

# % by correct by the code of the triad answer
print(percentage_by_answer)

# Incorrect response data
print(datafalse)

# Overall summary stats
print(summary_stats)
```